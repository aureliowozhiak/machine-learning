{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Matemática Para Machine Learning</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios - Otimização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando você se aventura em Machine Learning, um dos aspectos fundamentais do seu aprendizado é entender o processo de otimização pela descida do gradiente. A descida de gradiente é a espinha dorsal de um algoritmo de aprendizado de máquina moderno. \n",
    "\n",
    "Uma vez que você compreenda a descida do gradiente, as coisas começam a ficar mais claras e é fácil entender algoritmos diferentes. \n",
    "\n",
    "Vamos começar com alguns dados. Vamos criar um conjunto de dados linear com algum ruído gaussiano aleatório."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estilo para os gráficos\n",
    "plt.style.use(['ggplot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados aleatórios com relação linear e ruído\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)  # 4 e 3 representam theta0 e theta1, parâmetros do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dos dados\n",
    "plt.plot(X,y,'b.')\n",
    "plt.xlabel(\"$x$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "_ = plt.axis([0,2,0,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É evidente que Y tem um bom relacionamento linear com X. Esses dados são muito simples e possuem apenas uma variável independente X.\n",
    "\n",
    "Um algoritmo de regressão linear simples pode ser representado pela fórmula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/form1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E então você pode resolver a equação para b e m da seguinte maneira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/form2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso é chamado de método analítico de resolver a equação. Nada de errado nisso, no entanto, lembre-se de que o aprendizado de máquina automatiza esta tarefa. \n",
    "\n",
    "Em Machine Learning, posso expressar a equação de uma linha de uma maneira diferente. Eu chamaria y como minha hipótese e a representaria como J (theta) e chamaria b como theta0 e m como theta1. Eu posso escrever a mesma equação como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/form3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1 - Como você resolveria o problema acima de forma analítica (sem usar Machine Learning)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2 - Usando os parâmetros encontrados no item 1, faça previsões com os novos valores de x apresentados abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3 - Crie o gráfico que representa os dados de x e y no item anterior e a linha de regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "A equação para calcular função de custo e gradientes será mostrada abaixo. Note que a função de custo é para regressão linear. Para outros algoritmos, a função de custo será diferente e os gradientes teriam que ser derivados das funções de custo.\n",
    "\n",
    "m = número de observações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/form4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos usando um exemplo de regressão linear. Você começa com um vetor Theta aleatório e prediz o h(Theta), então deduz o custo usando a equação acima que significa Erro Quadrático Médio (MSE). Na sequência, minimizamos o custo para calcular o próximo passo (ou Theta). A derivada parcial é algo que pode ajudar a encontrar Theta para a próxima iteração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas espere atualmente precisamos calcular Theta0 e Theta1. Como fazer isso se tivéssemos vários recursos (variáveis de entrada), pois teríamos vários \"Theta\"? Não se preocupe, aqui está a forma geral para calcular Theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/form5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você está pronto para escrever seu primeiro algoritmo de descida do gradiente. Embora possa parecer esmagador no início, não é tão complexo quanto parece.\n",
    "\n",
    "Do que precisamos? De uma função de custo e de uma função para a descida do gradiente. Está pronto?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4 - Desenvolva uma função em Python para a função de custo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  cal_cost(theta, X, y):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5 - Desenvolva uma função em Python para a otimização com a descida do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta, learning_rate = 0.01, iterations = 100):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de aprendiado\n",
    "lr = 0.01\n",
    "\n",
    "# Número de iterações de treinamento\n",
    "n_iter = 1000\n",
    "\n",
    "# Inicializamos os parâmetros com valores aletórios\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "# Valores de entrada X e bias\n",
    "X_b = np.c_[np.ones((len(X),1)),X]\n",
    "\n",
    "# Treinamento\n",
    "theta, cost_history, theta_history = gradient_descent(X_b, y, theta, lr, n_iter)\n",
    "\n",
    "\n",
    "print('Theta0:          {:0.3f}, \\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0]))\n",
    "print('Custo Final/MSE:  {:0.3f}'.format(cost_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico com as iterações e os parâmetros aprendidos no treinamento\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.set_ylabel('J(Theta)')\n",
    "ax.set_xlabel('Iterações')\n",
    "_=ax.plot(range(n_iter),cost_history,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para o plot do treinamento com diferentes taxas de aprendizado\n",
    "def plot_GD(n_iter,lr,ax,ax1=None):\n",
    "     \"\"\"\n",
    "     n_iter = número de iterações\n",
    "     lr = Learning Rate\n",
    "     ax = Axis to plot the Gradient Descent\n",
    "     ax1 = Axis to plot cost_history vs Iterations plot\n",
    "\n",
    "     \"\"\"\n",
    "     _ = ax.plot(X,y,'b.')\n",
    "     theta = np.random.randn(2,1)\n",
    "\n",
    "     tr = 0.1\n",
    "     cost_history = np.zeros(n_iter)\n",
    "     for i in range(n_iter):\n",
    "        pred_prev = X_b.dot(theta)\n",
    "        theta,h,_ = gradient_descent(X_b,y,theta,lr,1)\n",
    "        pred = X_b.dot(theta)\n",
    "\n",
    "        cost_history[i] = h[0]\n",
    "\n",
    "        if ((i % 25 == 0) ):\n",
    "            _ = ax.plot(X,pred,'r-',alpha=tr)\n",
    "            if tr < 0.8:\n",
    "                tr = tr + 0.2\n",
    "     if not ax1== None:\n",
    "        _ = ax1.plot(range(n_iter),cost_history,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot do treinamento - comparando diferentes taxas de aprendizado\n",
    "fig = plt.figure(figsize=(30,25),dpi=200)\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "it_lr = [(2000,0.001),(500,0.01),(200,0.05),(100,0.1)]\n",
    "count = 0\n",
    "for n_iter, lr in it_lr:\n",
    "    count += 1\n",
    "    \n",
    "    ax = fig.add_subplot(4, 2, count)\n",
    "    count += 1\n",
    "   \n",
    "    ax1 = fig.add_subplot(4,2,count)\n",
    "    \n",
    "    ax.set_title(\"Taxa de Aprendizado: {}\".format(lr))\n",
    "    ax1.set_title(\"Iterações: {}\".format(n_iter))\n",
    "    plot_GD(n_iter,lr,ax,ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique como, com pequenas taxas de aprendizado, leva muito tempo para convergir para a solução, enquanto que, com as taxas de aprendizado maiores, é mais rápido.\n",
    "\n",
    "Uma nota de cautela é que a taxa real de aprendizado do seu problema dependeria dos dados e não há uma fórmula geral para defini-la corretamente. No entanto, existem algoritmos de optimização sofisticados que começam com maiores taxas de aprendizagem e depois reduzem lentamente a taxa de aprendizagem à medida que nos aproximamos da solução, como por exemplo o Otimizador Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linhas de regressão (uma para cada modelo)\n",
    "_,ax = plt.subplots(figsize=(14,10))\n",
    "plot_GD(100,0.1,ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em nosso algoritmo de gradiente descendente fizemos os gradientes em cada observação um por um. Mas com gradiente descendente estocástico podemos escolher aleatoriamente as observações. É chamado de estocástico porque as amostras são selecionadas aleatoriamente (ou embaralhadas) em vez de usar um único grupo (como na descida de gradiente padrão) ou na ordem em que aparecem no conjunto de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6 - Desenvolva uma função em Python para a otimização com a descida estocástica do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocashtic_gradient_descent(X,y,theta,learning_rate=0.01,iterations=10):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "lr = 0.5\n",
    "n_iter = 50\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "X_b = np.c_[np.ones((len(X),1)),X]\n",
    "theta,cost_history = stocashtic_gradient_descent(X_b,y,theta,lr,n_iter)\n",
    "\n",
    "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0]))\n",
    "print('Custo Final/MSE:  {:0.3f}'.format(cost_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.set_ylabel('{J(Theta)}',rotation=0)\n",
    "ax.set_xlabel('{Iterations}')\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "_=ax.plot(range(n_iter),cost_history,'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, usamos uma abordagem chamada descida do gradiente em mini-lote. Essa abordagem usa amostras aleatórias, mas em lotes. O que isso significa é que não calculamos os gradientes para cada observação, mas para um grupo de observações que resulta em uma otimização mais rápida. Uma maneira simples de implementar é embaralhar as observações e, em seguida, criar lotes e prosseguir com a descida de gradiente usando lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7 - Desenvolva uma função em Python para a otimização com a descida do gradiente em mini-lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_gradient_descent(X, y, theta, learning_rate = 0.01, iterations = 10, batch_size = 20):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "lr = 0.1\n",
    "n_iter = 200\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "theta,cost_history = minibatch_gradient_descent(X, y, theta, lr, n_iter)\n",
    "\n",
    "print('Theta0:          {:0.3f},\\nTheta1:          {:0.3f}'.format(theta[0][0],theta[1][0]))\n",
    "print('Custo Final/MSE:  {:0.3f}'.format(cost_history[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "ax.set_ylabel('{J(Theta)}',rotation=0)\n",
    "ax.set_xlabel('{Iterações}')\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "_ = ax.plot(range(n_iter),cost_history,'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
